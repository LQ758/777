import os
import numpy as np
import traceback

# å¯¼å…¥éŸ³ç´ çº§è¯„åˆ†æ¨¡å—
try:
    from .éŸ³ç´ è¯„åˆ†æ¨¡å— import PhonemeScorer, DetailedPronunciationResult
    from .éŸ³ç´ ç‰¹å¾æå– import AcousticFeatureExtractor, PhonemeAligner, PronunciationQualityAssessor
    PHONEME_SCORING_AVAILABLE = True
    print('âœ… éŸ³ç´ çº§è¯„åˆ†æ¨¡å—åŠ è½½æˆåŠŸ')
except ImportError as e:
    print(f'âš ï¸ éŸ³ç´ çº§è¯„åˆ†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
    PHONEME_SCORING_AVAILABLE = False

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶çš„ä¾èµ–é—®é¢˜
def _import_dependencies():
    """å»¶è¿Ÿå¯¼å…¥ä¾èµ–åº“ï¼Œå‡å°‘Flaské‡è½½è§¦å‘"""
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡å‡å°‘åº“çš„è°ƒè¯•è¾“å‡º
        import os
        os.environ.setdefault('TF_CPP_MIN_LOG_LEVEL', '2')
        os.environ.setdefault('PYTORCH_DISABLE_VERSION_CHECK', '1')
        
        import torch
        from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
        import librosa
        return torch, Wav2Vec2Processor, Wav2Vec2ForCTC, librosa
    except ImportError as e:
        print(f"ä¾èµ–åº“å¯¼å…¥å¤±è´¥: {e}")
        return None, None, None, None

def record_audio(duration=3, sr=16000):
    """å½•éŸ³å‡½æ•°ï¼Œè¿”å›éŸ³é¢‘æ•°æ®"""
    try:
        import sounddevice as sd
        print("ğŸ™ï¸ å½•éŸ³å¼€å§‹... æŒ‰ä¸‹å›è½¦ç»“æŸï¼ˆ3ç§’ï¼‰")
        audio = sd.rec(int(duration * sr), samplerate=sr, channels=1)
        sd.wait()  # ç­‰å¾…å½•éŸ³å®Œæˆ
        return audio.flatten()
    except ImportError:
        print("è­¦å‘Š: sounddeviceåº“æœªå®‰è£…ï¼Œæ— æ³•å½•éŸ³")
        return np.zeros(sr * duration)

def score_pronunciation(audio_data, reference_text, detailed=False):
    """ä½¿ç”¨ Wav2Vec2 è¯„ä¼°å‘éŸ³å‡†ç¡®æ€§
    
    Args:
        audio_data: éŸ³é¢‘æ•°æ®
        reference_text: å‚è€ƒæ–‡æœ¬
        detailed: æ˜¯å¦è¿”å›éŸ³ç´ çº§è¯¦ç»†è¯„åˆ†
    
    Returns:
        floatæˆ–DetailedPronunciationResult: ç®€å•è¯„åˆ†æˆ–è¯¦ç»†è¯„åˆ†ç»“æœ
    """
    try:
        # å»¶è¿Ÿå¯¼å…¥ä¾èµ–
        torch, Wav2Vec2Processor, Wav2Vec2ForCTC, librosa = _import_dependencies()
        
        if torch is None:
            raise ImportError("å¿…è¦çš„ä¾èµ–åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install -r requirements.txt")
        
        # æ£€æŸ¥éŸ³é¢‘æ•°æ®
        if audio_data is None or len(audio_data) == 0:
            raise ValueError("éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        print(f"éŸ³é¢‘æ•°æ®é•¿åº¦: {len(audio_data)} é‡‡æ ·ç‚¹")
        
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œç¡®ä¿åœ¨ä¸åŒç¯å¢ƒä¸‹éƒ½èƒ½æ‰¾åˆ°æ¨¡å‹
        model_name = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data", "models", "wav2vec2-base-960h")
        
        if not os.path.exists(model_name):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_name}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
        required_files = ['config.json', 'pytorch_model.bin', 'vocab.json']
        for file in required_files:
            file_path = os.path.join(model_name, file)
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ç¼ºå¤±: {file_path}")
        
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        
        # è®¾ç½®è®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
        processor = Wav2Vec2Processor.from_pretrained(model_name)
        model = Wav2Vec2ForCTC.from_pretrained(model_name)
        model = model.to(device)
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        print("æ¨¡å‹åŠ è½½æˆåŠŸ")

        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯float32ç±»å‹
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)
        
        # éŸ³é¢‘æ•°æ®å½’ä¸€åŒ–
        if np.max(np.abs(audio_data)) > 0:
            audio_data = audio_data / np.max(np.abs(audio_data))
        
        print("éŸ³é¢‘é¢„å¤„ç†å®Œæˆ")

        # å°†éŸ³é¢‘æ•°æ®è½¬ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        inputs = processor(audio_data, sampling_rate=16000, return_tensors="pt", padding=True)
        # æ³¨æ„ï¼šprocessorè¿”å›çš„æ˜¯ä¸€ä¸ªå­—å…¸/BatchFeatureï¼Œéœ€ä½¿ç”¨**è§£åŒ…æˆ–é€šè¿‡é”®è®¿é—®
        inputs = {k: v.to(device) for k, v in dict(inputs).items()}
        
        print("å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        
        # æ¨ç†
        with torch.no_grad():
            # æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼šä½¿ç”¨å…³é”®å­—å‚æ•°è§£åŒ…ï¼Œé¿å…å±æ€§è®¿é—®é”™è¯¯
            logits = model(**inputs).logits
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.batch_decode(predicted_ids)[0]
        print(f"è¯­éŸ³è¯†åˆ«ç»“æœ: {transcription}")

        # è¯„åˆ†é€»è¾‘ï¼ˆåŸºäº Levenshtein è·ç¦»ï¼‰
        try:
            from Levenshtein import distance
            print("ä½¿ç”¨Levenshteinè·ç¦»è®¡ç®—ç›¸ä¼¼åº¦")
        except ImportError:
            try:
                from python_Levenshtein import distance
                print("ä½¿ç”¨python-Levenshteinè·ç¦»è®¡ç®—ç›¸ä¼¼åº¦")
            except ImportError:
                # å¦‚æœæ²¡æœ‰Levenshteinåº“ï¼Œä½¿ç”¨æ”¹è¿›çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ç®—æ³•
                print("è­¦å‘Š: æœªæ‰¾åˆ°Levenshteinåº“ï¼Œä½¿ç”¨æ”¹è¿›çš„ç›¸ä¼¼åº¦è®¡ç®—")
                def improved_similarity(str1, str2):
                    str1, str2 = str1.lower().strip(), str2.lower().strip()
                    if len(str1) == 0 or len(str2) == 0:
                        return 0
                    
                    # è®¡ç®—å­—ç¬¦çº§åˆ«çš„ç›¸ä¼¼åº¦
                    char_similarity = sum(1 for c in str1 if c in str2) / max(len(str1), len(str2))
                    
                    # è®¡ç®—å•è¯çº§åˆ«çš„ç›¸ä¼¼åº¦
                    words1 = set(str1.split())
                    words2 = set(str2.split())
                    if len(words1) == 0 or len(words2) == 0:
                        word_similarity = 0
                    else:
                        word_similarity = len(words1.intersection(words2)) / max(len(words1), len(words2))
                    
                    # ç»¼åˆè¯„åˆ†
                    return (char_similarity * 0.4 + word_similarity * 0.6)
                
                score = 100 * improved_similarity(transcription, reference_text)
                final_score = max(0, min(score, 100))
                print(f"æ”¹è¿›ç›¸ä¼¼åº¦è¯„åˆ†å®Œæˆ: {final_score}")
                return final_score

        # ä½¿ç”¨Levenshteinè·ç¦»è®¡ç®—
        distance_score = distance(transcription.lower(), reference_text.lower())
        max_distance = max(len(transcription), len(reference_text))
        
        if max_distance == 0:
            similarity = 1.0
            score = 100
        else:
            similarity = 1 - (distance_score / max_distance)
            score = 100 * similarity
        
        final_score = max(0, min(score, 100))
        print(f"Levenshteinè·ç¦»è¯„åˆ†å®Œæˆ: {final_score}")
        print(f"  è½¬å½•æ–‡æœ¬: '{transcription}'")
        print(f"  å‚è€ƒæ–‡æœ¬: '{reference_text}'")
        print(f"  ç¼–è¾‘è·ç¦»: {distance_score}")
        print(f"  æœ€å¤§é•¿åº¦: {max_distance}")
        print(f"  ç›¸ä¼¼åº¦: {similarity:.3f}")
        
        # å¦‚æœéœ€è¦è¯¦ç»†è¯„åˆ†ä¸”éŸ³ç´ æ¨¡å—å¯ç”¨ï¼Œè¿›è¡ŒéŸ³ç´ çº§åˆ†æ
        if detailed and PHONEME_SCORING_AVAILABLE:
            try:
                print("å¼€å§‹éŸ³ç´ çº§è¯¦ç»†åˆ†æ...")
                phoneme_scorer = PhonemeScorer()
                detailed_result = phoneme_scorer.analyze_pronunciation_detailed(
                    audio_data, reference_text, model, processor, sr=16000
                )
                # ä½¿ç”¨éŸ³ç´ çº§è¯„åˆ†ä½œä¸ºæœ€ç»ˆè¯„åˆ†
                detailed_result.overall_score = max(detailed_result.overall_score, final_score * 0.8)
                print(f"éŸ³ç´ çº§åˆ†æå®Œæˆï¼Œæœ€ç»ˆè¯„åˆ†: {detailed_result.overall_score:.1f}")
                return detailed_result
            except Exception as e:
                print(f"éŸ³ç´ çº§åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°ç®€å•è¯„åˆ†: {e}")
                # å¦‚æœéŸ³ç´ çº§åˆ†æå¤±è´¥ï¼Œè¿”å›ç®€å•è¯„åˆ†åŒ…è£…æˆè¯¦ç»†ç»“æœ
                if detailed:
                    return create_simple_detailed_result(final_score, transcription, reference_text)
        
        # å¦‚æœä¸éœ€è¦è¯¦ç»†è¯„åˆ†æˆ–éŸ³ç´ æ¨¡å—ä¸å¯ç”¨ï¼Œè¿”å›ç®€å•è¯„åˆ†
        if detailed:
            return create_simple_detailed_result(final_score, transcription, reference_text)
        
        return final_score
        
    except Exception as e:
        print(f"å‘éŸ³è¯„åˆ†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        traceback.print_exc()
        
        # æä¾›å…·ä½“çš„é”™è¯¯ä¿¡æ¯å’Œå»ºè®®
        if "CUDA" in str(e):
            error_msg = "GPUå†…å­˜ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨CPUæ¨¡å¼æˆ–å‡å°‘éŸ³é¢‘é•¿åº¦"
        elif "model" in str(e).lower():
            error_msg = "æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´"
        elif "audio" in str(e).lower():
            error_msg = "éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ ¼å¼å’Œé•¿åº¦"
        else:
            error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)}"
        
        print(f"é”™è¯¯è¯¦æƒ…: {error_msg}")
        raise RuntimeError(f"å‘éŸ³è¯„åˆ†å¤±è´¥: {error_msg}")


def create_simple_detailed_result(score: float, transcription: str, reference_text: str):
    """åˆ›å»ºç®€åŒ–çš„è¯¦ç»†è¯„åˆ†ç»“æœ"""
    if not PHONEME_SCORING_AVAILABLE:
        # å¦‚æœéŸ³ç´ æ¨¡å—ä¸å¯ç”¨ï¼Œè¿”å›ç®€å•çš„å­—å…¸ç»“æœ
        return {
            'overall_score': score,
            'transcription': transcription,
            'reference_text': reference_text,
            'phoneme_scores': [],
            'pronunciation_issues': [],
            'improvement_suggestions': ['è¯·æ£€æŸ¥å‘éŸ³èŠ‚å¥å’Œæ¸…æ™°åº¦'],
            'detailed_available': False
        }
    
    # ä½¿ç”¨DetailedPronunciationResultç±»
    from .éŸ³ç´ è¯„åˆ†æ¨¡å— import DetailedPronunciationResult
    
    return DetailedPronunciationResult(
        overall_score=score,
        phoneme_scores=[],
        word_scores=[],
        pronunciation_issues=['æœªè¿›è¡ŒéŸ³ç´ çº§åˆ†æ'],
        improvement_suggestions=['å»ºè®®å¤šç»ƒä¹ å‘éŸ³æ¸…æ™°åº¦'],
        duration_analysis={'total_duration': 0},
        pitch_analysis={}
    )


def score_pronunciation_detailed(audio_data, reference_text):
    """è¿”å›è¯¦ç»†å‘éŸ³è¯„åˆ†ç»“æœ"""
    return score_pronunciation(audio_data, reference_text, detailed=True)